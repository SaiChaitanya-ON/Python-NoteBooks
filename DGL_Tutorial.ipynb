{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import itertools\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "   \n",
    "\n",
    "class GraphVisualization:\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "\n",
    "        self.visual = []\n",
    "\n",
    "    def addEdge(self, a, b):\n",
    "        temp = [a, b]\n",
    "        self.visual.append(temp)\n",
    "\n",
    "\n",
    "    def visualize(self):\n",
    "        G = nx.Graph()\n",
    "        G.add_edges_from(self.visual)\n",
    "        nx.draw_networkx(G,node_color='grey')\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "G = GraphVisualization()\n",
    "G.addEdge(0, 1)\n",
    "G.addEdge(0, 2)\n",
    "G.addEdge(1, 2)\n",
    "G.addEdge(0, 3)\n",
    "G.addEdge(0, 4)\n",
    "G.addEdge(3, 4)\n",
    "G.addEdge(0, 5)\n",
    "\n",
    "G.visualize()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "import dgl\n",
    "import numpy as np\n",
    "\n",
    "g = dgl.graph(([0, 0, 1, 0, 0, 3, 0], [1, 2, 2, 3, 4, 4, 5]), num_nodes=6)\n",
    "\n",
    "#g = dgl.graph(([0, 0, 1, 0, 0, 3, 0], [1, 2, 2, 3, 4, 4, 5]))\n",
    "\n",
    "print(g.ndata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=6, num_edges=7,\n",
      "      ndata_schemes={'a': Scheme(shape=(3,), dtype=torch.float32), 'y': Scheme(shape=(5, 4), dtype=torch.float32)}\n",
      "      edata_schemes={})\n",
      "tensor([0, 1, 2, 3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "g.ndata['a'] = torch.randn(6, 3)\n",
    "\n",
    "#g.edata['b'] = torch.randn(7, 4)\n",
    "\n",
    "g.ndata['y'] = torch.randn(6, 5, 4)\n",
    "\n",
    "# print(\"Node Data: \",g.ndata)\n",
    "# print(\"Edge Data: \",g.edata)\n",
    "print(g)\n",
    "print(g.nodes())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "7\n",
      "5\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(g.num_nodes())\n",
    "print(g.num_edges())\n",
    "\n",
    "print(g.out_degrees(0))\n",
    "print(g.in_degrees(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Node Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading /root/.dgl/cora_v2.zip from https://data.dgl.ai/dataset/cora_v2.zip...\n",
      "Extracting file to /root/.dgl/cora_v2\n",
      "Finished data loading and preprocessing.\n",
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done saving data into cached files.\n",
      "Features tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]])\n",
      "Features.shape torch.Size([2708, 1433])\n",
      "Labels tensor([3, 4, 4,  ..., 3, 3, 3])\n",
      "Train Mask tensor([ True,  True,  True,  ..., False, False, False])\n",
      "len(Train Mask) 2708\n"
     ]
    }
   ],
   "source": [
    "import dgl.data\n",
    "\n",
    "dataset = dgl.data.CoraGraphDataset()\n",
    "g = dataset[0]\n",
    "features = g.ndata['feat']\n",
    "print('Features',features)\n",
    "print('Features.shape',features.shape)\n",
    "labels = g.ndata['label']\n",
    "print('Labels',labels)\n",
    "train_mask = g.ndata['train_mask']\n",
    "print('Train Mask',train_mask)\n",
    "print('len(Train Mask)',len(train_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import GraphConv\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, num_classes)\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "#         print(\"layer 1: \", h)\n",
    "#         print(\"layer 1 shape: \", h.shape)\n",
    "        h = F.relu(h)\n",
    "#         print(\"Relu: \", h)\n",
    "        h = self.conv2(g, h)\n",
    "#         print(\"layer 2: \", h)\n",
    "#         print(\"layer 2 shape: \", h.shape)\n",
    "        \n",
    "        return h\n",
    "\n",
    "# Create the model with given dimensions\n",
    "model = GCN(g.ndata['feat'].shape[1], 16, dataset.num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits.shape torch.Size([2708, 7])\n",
      "Logits tensor([[ 0.0046, -0.0046, -0.0040,  ...,  0.0020,  0.0003,  0.0043],\n",
      "        [ 0.0010, -0.0015, -0.0030,  ...,  0.0027,  0.0008,  0.0016],\n",
      "        [ 0.0032, -0.0041, -0.0023,  ...,  0.0028, -0.0014,  0.0036],\n",
      "        ...,\n",
      "        [ 0.0107, -0.0036, -0.0016,  ...,  0.0024, -0.0029,  0.0066],\n",
      "        [ 0.0034, -0.0026, -0.0042,  ..., -0.0028, -0.0040,  0.0012],\n",
      "        [ 0.0022, -0.0023, -0.0032,  ..., -0.0016, -0.0017,  0.0010]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "Pred tensor([3, 4, 6,  ..., 0, 0, 3])\n",
      "len(Pred) 2708\n"
     ]
    }
   ],
   "source": [
    "def train(g, model):\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "    best_val_acc = 0\n",
    "    best_test_acc = 0\n",
    "\n",
    "    features = g.ndata['feat']\n",
    "    labels = g.ndata['label']\n",
    "    train_mask = g.ndata['train_mask']\n",
    "    val_mask = g.ndata['val_mask']\n",
    "    test_mask = g.ndata['test_mask']\n",
    "    \n",
    "    #for e in range(100):\n",
    "    # Forward\n",
    "    logits = model(g, features)\n",
    "    print('Logits.shape', logits.shape)\n",
    "    print('Logits', logits)\n",
    "\n",
    "    # Compute prediction\n",
    "    pred = logits.argmax(1)\n",
    "    print('Pred', pred)\n",
    "    print('len(Pred)', len(pred))\n",
    "\n",
    "    # Compute loss\n",
    "    # Note that you should only compute the losses of the nodes in the training set.\n",
    "    loss = F.cross_entropy(logits[train_mask], labels[train_mask])\n",
    "\n",
    "    # Compute accuracy on training/validation/test\n",
    "    train_acc = (pred[train_mask] == labels[train_mask]).float().mean()\n",
    "#         print('pred[train_mast] == labels[train_mask]',(pred[train_mask]==labels[train_mask]).float().mean())\n",
    "#         print('len(pred[train_mast])',len(pred[train_mask]))\n",
    "    val_acc = (pred[val_mask] == labels[val_mask]).float().mean()\n",
    "    test_acc = (pred[test_mask] == labels[test_mask]).float().mean()\n",
    "\n",
    "    # Save the best validation accuracy and the corresponding test accuracy.\n",
    "    if best_val_acc < val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_test_acc = test_acc\n",
    "\n",
    "    # Backward\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "#     if e % 5 == 0:\n",
    "#         print('In epoch {}, loss: {:.3f}, val acc: {:.3f} (best {:.3f}), test acc: {:.3f} (best {:.3f})'.format(\n",
    "#             e, loss, val_acc, best_val_acc, test_acc, best_test_acc))\n",
    "\n",
    "            \n",
    "model = GCN(g.ndata['feat'].shape[1], 16, dataset.num_classes)\n",
    "train(g, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding Edge Weights to graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import EdgeWeightNorm, GraphConv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Self loop  (tensor([0, 1, 2, 3, 2, 5]), tensor([1, 2, 3, 4, 0, 3]))\n",
      "After Self loop  (tensor([0, 1, 2, 3, 2, 5, 0, 1, 2, 3, 4, 5]), tensor([1, 2, 3, 4, 0, 3, 0, 1, 2, 3, 4, 5]))\n",
      "Num of edges  12\n",
      "Length of edge_weight  12\n",
      "tensor([[2.3041, 1.4520],\n",
      "        [1.8190, 1.1463],\n",
      "        [1.9403, 1.2227],\n",
      "        [1.8190, 1.1463],\n",
      "        [2.0615, 1.2992],\n",
      "        [1.2127, 0.7642]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "g = dgl.graph(([0,1,2,3,2,5], [1,2,3,4,0,3]))\n",
    "print(\"Before Self loop \",g.edges())\n",
    "g = dgl.add_self_loop(g)\n",
    "print(\"After Self loop \",g.edges())\n",
    "feat = th.ones(6, 10)\n",
    "#print(\"features \",feat)\n",
    "print(\"Num of edges \",g.num_edges())\n",
    "edge_weight = th.tensor([0.5, 0.6, 0.4, 0.7, 0.9, 0.1, 1, 1, 1, 1, 1, 1])\n",
    "print(\"Length of edge_weight \",len(edge_weight))\n",
    "# norm = EdgeWeightNorm(norm='both')\n",
    "# norm_edge_weight = norm(g, edge_weight)\n",
    "#print(\"norm_edge_weight \",norm_edge_weight)\n",
    "conv = GraphConv(10, 2, norm='none', weight=True, bias=True)\n",
    "res = conv(g, feat, edge_weight=edge_weight)\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Link Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "import dgl.data\n",
    "\n",
    "dataset = dgl.data.CoraGraphDataset()\n",
    "g = dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no.of edges  10556\n",
      "eids  [    0     1     2 ... 10553 10554 10555]\n",
      "eids  10556\n",
      "eids  [6427 3197 4862 ... 4732 3591 5704]\n",
      "eids  10556\n",
      "neg_u:  [   0    0    0 ... 2707 2707 2707] neg_v:  [   1    2    3 ... 2703 2704 2705]\n"
     ]
    }
   ],
   "source": [
    "# Split edge set for training and testing\n",
    "u, v = g.edges()\n",
    "\n",
    "eids = np.arange(g.number_of_edges())\n",
    "print(\"no.of edges \",g.number_of_edges())\n",
    "print(\"eids \",eids)\n",
    "print(\"eids \",len(eids))\n",
    "eids = np.random.permutation(eids)\n",
    "print(\"eids \",eids)\n",
    "print(\"eids \",len(eids))\n",
    "test_size = int(len(eids) * 0.1)\n",
    "train_size = g.number_of_edges() - test_size\n",
    "test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]\n",
    "train_pos_u, train_pos_v = u[eids[test_size:]], v[eids[test_size:]]\n",
    "\n",
    "# Find all negative edges and split them for training and testing\n",
    "adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())))\n",
    "#print(\"adj: \",adj)\n",
    "adj_neg = 1 - adj.todense() - np.eye(g.number_of_nodes())\n",
    "#print(\"adj_neg: \",adj_neg)\n",
    "neg_u, neg_v = np.where(adj_neg != 0)\n",
    "print(\"neg_u: \",neg_u, \"neg_v: \", neg_v)\n",
    "\n",
    "neg_eids = np.random.choice(len(neg_u), g.number_of_edges())\n",
    "test_neg_u, test_neg_v = neg_u[neg_eids[:test_size]], neg_v[neg_eids[:test_size]]\n",
    "train_neg_u, train_neg_v = neg_u[neg_eids[test_size:]], neg_v[neg_eids[test_size:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_g = dgl.remove_edges(g, eids[:test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import SAGEConv\n",
    "\n",
    "# ----------- 2. create model -------------- #\n",
    "# build a two-layer GraphSAGE model\n",
    "class GraphSAGE(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats):\n",
    "        super(GraphSAGE, self).__init__()\n",
    "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
    "        self.conv2 = SAGEConv(h_feats, h_feats, 'mean')\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        h = self.conv1(g, in_feat)\n",
    "#         print(\"layer 1: \", h)\n",
    "#         print(\"layer 1 shape: \", h.shape)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "#         print(\"layer 2: \", h)\n",
    "#         print(\"layer 2 shape: \", h.shape)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Pos Graph:  Graph(num_nodes=2708, num_edges=9501,\n",
      "      ndata_schemes={}\n",
      "      edata_schemes={})\n",
      "Train Neg Graph:  Graph(num_nodes=2708, num_edges=9501,\n",
      "      ndata_schemes={}\n",
      "      edata_schemes={})\n",
      "Test Pos Graph:  Graph(num_nodes=2708, num_edges=1055,\n",
      "      ndata_schemes={}\n",
      "      edata_schemes={})\n",
      "Test Neg Graph:  Graph(num_nodes=2708, num_edges=1055,\n",
      "      ndata_schemes={}\n",
      "      edata_schemes={})\n"
     ]
    }
   ],
   "source": [
    "train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=g.number_of_nodes())\n",
    "print(\"Train Pos Graph: \", train_pos_g)\n",
    "train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=g.number_of_nodes())\n",
    "print(\"Train Neg Graph: \", train_neg_g)\n",
    "\n",
    "\n",
    "test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=g.number_of_nodes())\n",
    "print(\"Test Pos Graph: \", test_pos_g)\n",
    "test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=g.number_of_nodes())\n",
    "print(\"Test Neg Graph: \", test_neg_g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dgl.function as fn\n",
    "\n",
    "class DotPredictor(nn.Module):\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            # Compute a new edge feature named 'score' by a dot-product between the\n",
    "            # source node feature 'h' and destination node feature 'h'.\n",
    "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
    "            # u_dot_v returns a 1-element vector for each edge so you need to squeeze it.\n",
    "            return g.edata['score'][:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPPredictor(nn.Module):\n",
    "    def __init__(self, h_feats):\n",
    "        super().__init__()\n",
    "        self.W1 = nn.Linear(h_feats * 2, h_feats)\n",
    "        self.W2 = nn.Linear(h_feats, 1)\n",
    "\n",
    "    def apply_edges(self, edges):\n",
    "        \"\"\"\n",
    "        Computes a scalar score for each edge of the given graph.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        edges :\n",
    "            Has three members ``src``, ``dst`` and ``data``, each of\n",
    "            which is a dictionary representing the features of the\n",
    "            source nodes, the destination nodes, and the edges\n",
    "            themselves.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            A dictionary of new edge features.\n",
    "        \"\"\"\n",
    "        h = torch.cat([edges.src['h'], edges.dst['h']], 1)\n",
    "        return {'score': self.W2(F.relu(self.W1(h))).squeeze(1)}\n",
    "\n",
    "    def forward(self, g, h):\n",
    "        with g.local_scope():\n",
    "            g.ndata['h'] = h\n",
    "            g.apply_edges(self.apply_edges)\n",
    "            return g.edata['score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GraphSAGE(train_g.ndata['feat'].shape[1], 16)\n",
    "# You can replace DotPredictor with MLPPredictor.\n",
    "#pred = MLPPredictor(16)\n",
    "pred = DotPredictor()\n",
    "\n",
    "def compute_loss(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score])\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
    "    return F.binary_cross_entropy_with_logits(scores, labels)\n",
    "\n",
    "def compute_auc(pos_score, neg_score):\n",
    "    scores = torch.cat([pos_score, neg_score]).numpy()\n",
    "    labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
    "    return roc_auc_score(labels, scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "h:  tensor([[-0.0250,  0.0098,  0.0387,  ..., -0.0058,  0.0238,  0.0156],\n",
      "        [-0.0212,  0.0154,  0.0192,  ..., -0.0197,  0.0494, -0.0374],\n",
      "        [-0.0310,  0.0049,  0.0393,  ..., -0.0118, -0.0049, -0.0139],\n",
      "        ...,\n",
      "        [ 0.0242, -0.0044, -0.0237,  ..., -0.0847,  0.0238,  0.0027],\n",
      "        [-0.0281,  0.0359,  0.0130,  ..., -0.0218,  0.0167,  0.0027],\n",
      "        [-0.0048,  0.0167,  0.0175,  ..., -0.0224,  0.0007, -0.0290]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "pos_score:  tensor([0.0024, 0.0003, 0.0007,  ..., 0.0063, 0.0034, 0.0027],\n",
      "       grad_fn=<SelectBackward>)\n",
      "neg_score:  tensor([0.0028, 0.0037, 0.0022,  ..., 0.0005, 0.0022, 0.0019],\n",
      "       grad_fn=<SelectBackward>)\n",
      "AUC 0.5537683340446081\n"
     ]
    }
   ],
   "source": [
    "# ----------- 3. set up loss and optimizer -------------- #\n",
    "# in this case, loss will in training loop\n",
    "optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=0.01)\n",
    "\n",
    "# ----------- 4. training -------------------------------- #\n",
    "all_logits = []\n",
    "\n",
    "#for e in range(100):\n",
    "# forward\n",
    "h = model(train_g, train_g.ndata['feat'])\n",
    "print(\"h: \", h)\n",
    "pos_score = pred(train_pos_g, h)\n",
    "print(\"pos_score: \", pos_score)\n",
    "neg_score = pred(train_neg_g, h)\n",
    "print(\"neg_score: \", neg_score)\n",
    "loss = compute_loss(pos_score, neg_score)\n",
    "\n",
    "# backward\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "optimizer.step()\n",
    "\n",
    "# if e % 5 == 0:\n",
    "#     print('In epoch {}, loss: {}'.format(e, loss))\n",
    "\n",
    "# ----------- 5. check results ------------------------ #\n",
    "from sklearn.metrics import roc_auc_score\n",
    "with torch.no_grad():\n",
    "    pos_score = pred(test_pos_g, h)\n",
    "    neg_score = pred(test_neg_g, h)\n",
    "    print('AUC', compute_auc(pos_score, neg_score))\n",
    "\n",
    "\n",
    "# Thumbnail Courtesy: Link Prediction with Neo4j, Mark Needham\n",
    "# sphinx_gallery_thumbnail_path = '_static/blitz_4_link_predict.png'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Graph Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1113\n"
     ]
    }
   ],
   "source": [
    "import dgl.data\n",
    "import torch\n",
    "\n",
    "# Generate a synthetic dataset with 10000 graphs, ranging from 10 to 500 nodes.\n",
    "dataset = dgl.data.GINDataset('PROTEINS', self_loop=True)\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node feature dimensionality: 3\n",
      "Number of graph categories: 2\n"
     ]
    }
   ],
   "source": [
    "print('Node feature dimensionality:', dataset.dim_nfeats)\n",
    "print('Number of graph categories:', dataset.gclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_examples  1113\n",
      "num_train  890\n",
      "torch.arange(num_train) \n",
      "tensor(0)\n",
      "tensor(1)\n",
      "tensor(2)\n",
      "tensor(3)\n",
      "tensor(4)\n",
      "After Shuffling train_sampler\n",
      "tensor(130)\n",
      "tensor(659)\n",
      "tensor(129)\n",
      "tensor(87)\n",
      "tensor(869)\n",
      "tensor(867)\n"
     ]
    }
   ],
   "source": [
    "from dgl.dataloading import GraphDataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "num_examples = len(dataset)\n",
    "print(\"num_examples \",num_examples)\n",
    "num_train = int(num_examples * 0.8)\n",
    "print(\"num_train \",num_train)\n",
    "\n",
    "train_sampler = SubsetRandomSampler(torch.arange(num_train))\n",
    "#print(\"torch.arange(num_train) \",torch.arange(num_train))\n",
    "test_sampler = SubsetRandomSampler(torch.arange(num_train, num_examples))\n",
    "#print(\"torch.arange(num_train, num_examples) \",torch.arange(num_train, num_examples))\n",
    "\n",
    "print(\"torch.arange(num_train) \")\n",
    "for i in range(5):\n",
    "    print(torch.arange(num_train)[i])\n",
    "    \n",
    "count = 0\n",
    "print(\"After Shuffling train_sampler\")\n",
    "for i in train_sampler:\n",
    "    print(i)\n",
    "    count += 1\n",
    "    if count > 5:\n",
    "        break\n",
    "    \n",
    "    \n",
    "train_dataloader = GraphDataLoader(dataset, sampler=train_sampler, batch_size=5, drop_last=False)\n",
    "test_dataloader = GraphDataLoader(dataset, sampler=test_sampler, batch_size=5, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# it = iter(train_dataloader)\n",
    "# batch = next(it)\n",
    "# print(len(batch[0].ndata['attr']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batched_graph, labels = batch\n",
    "# print('Number of nodes for each graph element in the batch:', batched_graph.batch_num_nodes())\n",
    "# print('Number of edges for each graph element in the batch:', batched_graph.batch_num_edges())\n",
    "\n",
    "\n",
    "# graphs = dgl.unbatch(batched_graph)\n",
    "# print('The original graphs in the minibatch:')\n",
    "# print(graphs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dgl.nn import GraphConv\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, in_feats, h_feats, num_classes):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GraphConv(in_feats, h_feats)\n",
    "        self.conv2 = GraphConv(h_feats, num_classes)\n",
    "        #print(\"Dim of Input Features \", in_feats)\n",
    "\n",
    "    def forward(self, g, in_feat):\n",
    "        #print(\"Input Features \",in_feat)\n",
    "        #print(\"Length of Input Features \", len(in_feat))\n",
    "        h = self.conv1(g, in_feat)\n",
    "        h = F.relu(h)\n",
    "        h = self.conv2(g, h)\n",
    "        g.ndata['h'] = h\n",
    "        #print(\"g.ndata['h'] \", g.ndata['h'])\n",
    "        #print(\"Length of g.ndata['h'] \", len(g.ndata['h']))\n",
    "        #print(\"Mean of Nodes \", dgl.mean_nodes(g, 'h'))\n",
    "        return dgl.mean_nodes(g, 'h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num of Classes  2\n",
      "Test accuracy: 0.22869955156950672\n"
     ]
    }
   ],
   "source": [
    "# Create the model with given dimensions\n",
    "print(\"Num of Classes \", dataset.gclasses)\n",
    "model = GCN(dataset.dim_nfeats, 16, dataset.gclasses)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "for epoch in range(20):\n",
    "    for batched_graph, labels in train_dataloader:\n",
    "        #print(\"labels \",labels)\n",
    "        pred = model(batched_graph, batched_graph.ndata['attr'].float())\n",
    "        #print(\"Prediction \",pred)\n",
    "        \n",
    "        #print('Number of nodes for each graph element in the batch:', batched_graph.batch_num_nodes())\n",
    "\n",
    "        loss = F.cross_entropy(pred, labels)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "num_correct = 0\n",
    "num_tests = 0\n",
    "for batched_graph, labels in test_dataloader:\n",
    "    pred = model(batched_graph, batched_graph.ndata['attr'].float())\n",
    "    num_correct += (pred.argmax(1) == labels).sum().item()\n",
    "    num_tests += len(labels)\n",
    "\n",
    "print('Test accuracy:', num_correct / num_tests)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Creating our own dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Club  Age\n",
      "Id             \n",
      "0   Mr. Hi   44\n",
      "1   Mr. Hi   37\n",
      "2   Mr. Hi   37\n",
      "3   Mr. Hi   40\n",
      "4   Mr. Hi   30\n",
      "\n",
      "      Dst    Weight\n",
      "Src               \n",
      "0      1  0.043591\n",
      "0      2  0.282119\n",
      "0      3  0.370293\n",
      "0      4  0.730570\n",
      "0      5  0.821187\n"
     ]
    }
   ],
   "source": [
    "import urllib.request\n",
    "import pandas as pd\n",
    "urllib.request.urlretrieve('https://data.dgl.ai/tutorial/dataset/members.csv', './members.csv')\n",
    "urllib.request.urlretrieve('https://data.dgl.ai/tutorial/dataset/interactions.csv', './interactions.csv')\n",
    "\n",
    "members = pd.read_csv('./members.csv',index_col = 0)\n",
    "print(members.head())\n",
    "\n",
    "interactions = pd.read_csv('./interactions.csv',index_col = 0)\n",
    "print(\"\\n\",interactions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph(num_nodes=34, num_edges=156,\n",
      "      ndata_schemes={'feat': Scheme(shape=(), dtype=torch.int64), 'label': Scheme(shape=(), dtype=torch.int8), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool), 'test_mask': Scheme(shape=(), dtype=torch.bool)}\n",
      "      edata_schemes={'weight': Scheme(shape=(), dtype=torch.float64)})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/.cache/pypoetry/virtualenvs/oaknorth-ml-lib-QXhsOmlJ-py3.7/lib/python3.7/site-packages/ipykernel_launcher.py:12: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  /pytorch/torch/csrc/utils/tensor_numpy.cpp:141.)\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "from dgl.data import DGLDataset\n",
    "import os\n",
    "\n",
    "class KarateClubDataset(DGLDataset):\n",
    "    def __init__(self):\n",
    "        super().__init__(name='karate_club')\n",
    "\n",
    "    def process(self):\n",
    "        nodes_data = pd.read_csv('./members.csv')\n",
    "        edges_data = pd.read_csv('./interactions.csv')\n",
    "        node_features = torch.from_numpy(nodes_data['Age'].to_numpy())\n",
    "        node_labels = torch.from_numpy(nodes_data['Club'].astype('category').cat.codes.to_numpy())\n",
    "        edge_features = torch.from_numpy(edges_data['Weight'].to_numpy())\n",
    "        edges_src = torch.from_numpy(edges_data['Src'].to_numpy())\n",
    "        edges_dst = torch.from_numpy(edges_data['Dst'].to_numpy())\n",
    "\n",
    "        self.graph = dgl.graph((edges_src, edges_dst), num_nodes=nodes_data.shape[0])\n",
    "        self.graph.ndata['feat'] = node_features\n",
    "        self.graph.ndata['label'] = node_labels\n",
    "        self.graph.edata['weight'] = edge_features\n",
    "\n",
    "        # If your dataset is a node classification dataset, you will need to assign\n",
    "        # masks indicating whether a node belongs to training, validation, and test set.\n",
    "        n_nodes = nodes_data.shape[0]\n",
    "        n_train = int(n_nodes * 0.6)\n",
    "        n_val = int(n_nodes * 0.2)\n",
    "        train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        val_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "        train_mask[:n_train] = True\n",
    "        val_mask[n_train:n_train + n_val] = True\n",
    "        test_mask[n_train + n_val:] = True\n",
    "        self.graph.ndata['train_mask'] = train_mask\n",
    "        self.graph.ndata['val_mask'] = val_mask\n",
    "        self.graph.ndata['test_mask'] = test_mask\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.graph\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1\n",
    "\n",
    "dataset = KarateClubDataset()\n",
    "graph = dataset[0]\n",
    "\n",
    "print(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
